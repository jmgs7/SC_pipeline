---
title: "Run1_analysis"
author: "José Manuel Gómez Silva"
date: "`r Sys.Date()`"
output: # html_notebook
---

```{r setup, include=FALSE}
all_times <- list() # store the time for each chunk
knitr::knit_hooks$set(time_it = local({
  now <- NULL
  function(before, options) {
    if (before) {
      now <<- Sys.time()
    } else {
      res <- difftime(Sys.time(), now, units = "secs")
      all_times[[options$label]] <<- res
    }
  }
}))

knitr::opts_chunk$set(
  tidy = TRUE,
  tidy.opts = list(width.cutoff = 95),
  message = FALSE,
  warning = FALSE,
  time_it = TRUE,
  error = TRUE,
  echo = TRUE,
  engine.opts = list(bash = "-l")
)
```

# SC_Prostate_Run_1 analysis.

Analysis of scRNA-seq data provided by Eduardo Andrés León (eduardo.andres\@csic.es, Instituto de Parasitología y Biología López Neyra, Granada). SC data was generated and pre-analysed sing BD Rhapsody systems and Illumina sequencers. BD includes pipelines for read mapping and putative cell filtering. An analysis using the Seurat package (<https://satijalab.org/seurat/>) was done by the CSIC staff using the seven bridges platform, but an obsolete normalization method was used. This R markdown file describes a preliminary analysis for the first of the four runs the project contains.

```{r libraries, include = FALSE}
library(Seurat)
library(dplyr)
library(patchwork)
library(sctransform)
library(ggplot2)
library(celldex) # Cell annotation.
library(SingleR) # Cell annotation.
library(parallel) # detectCores()
library(future) # Allows parallelization in Seurat.
library(readODS) # Allows ods file import to add sample info
library(scDblFinder)
# Set up Seurat pararell computing.
options(parallelly.fork.enable = TRUE)
plan("multicore", workers = detectCores())

# Import user's libraries.
source(file = "~/Documents/SC_Prostate/Scripts/SC_utils/FeatureScatterGradient.R")
```

## 1. Import raw data.

We will use the raw data in order to visualize QC parameters.

```{r import_raw_data}

run1.raw <- readRDS("~/Documents/SC_Prostate/Data/run1/C1_Seurat.rds")
run1.raw$orig.ident <- "run1"
run1.raw <- SetIdent(run1.raw, value = run1.raw$orig.ident)
run1.raw
```

### 1.1. Adding sample names and sample groups.

```{r}

# Load information from .ods file
excel_data <- read_ods("~/Documents/SC_Prostate/Data/sample_info.ods")

# Specify the experiment you want to extract information for
target_run <- "run1"

# Filter Excel data for the specific experiment
filtered_excel_data <- excel_data %>%
  filter(Run == target_run)

# Extract the numeric part from Sample Tag and convert it to integer
run1.raw$Sample_Tag_Number <- as.integer(gsub("\\D", "", run1.raw$Sample_Tag))

# Extract Sample Name and Sample Group based on Sample Tag information
run1.raw$Sample_Name <- filtered_excel_data$Sample_Name[match(run1.raw$Sample_Tag_Number, filtered_excel_data$Sample_Tag)]

run1.raw$Sample_Group <- filtered_excel_data$Sample_Group[match(run1.raw$Sample_Tag_Number, filtered_excel_data$Sample_Tag)]

run1.raw$Sample_Name_Group <- filtered_excel_data$Sample_Name_Group[match(run1.raw$Sample_Tag_Number, filtered_excel_data$Sample_Tag)]
```

## 2. QC.

### 2.1. Mitochondrial gene percentage calculation.

```{r mito_genes}

run1.raw[["percent.mt"]] <- PercentageFeatureSet(run1.raw, pattern = "^MT-")
```

### 2.2. QC visualization.

What we can appreciate is a high proportion of cells with abundance of mitochondrial genes. Also, the distribution of the number of genes per cells shows an strange distribution, with a group of cells containing a low count fo features.

We can appreciate that the sample preprocessing done by the sequencing systems has automatically trimmed cells with less than 5K counts. Nevertheless, we suspect we could be losing important data, as the distribution of the read counts seems to have been cut right in the center of the curve.

The plotting of the % mitochondrial genes against read count shows a very disperse distribution, while the slope between counts and features is quasi linear.

```{r QC_visualization, fig.height=6, fig.width=10}

# Visualize QC metrics as a violin plot
VlnPlot(run1.raw, features = c("nFeature_RNA", "nCount_RNA", "percent.mt"), ncol = 3)

# Zoom in on nFeature_RNA violin plot.
VlnPlot(run1.raw, features = "nFeature_RNA", ncol = 1) + ylim(0, 2500) + NoLegend()

# Zoom in on nCount_RNA violin plot.
VlnPlot(run1.raw, features = "nCount_RNA", ncol = 1) + ylim(0, 25000) + NoLegend()

# Visualize relationships in metadata to detect outliers with FeatureScatter function
plot1 <- FeatureScatter(run1.raw, feature1 = "nCount_RNA", feature2 = "percent.mt")
plot2 <- FeatureScatterGradient(run1.raw, feature1 = "nCount_RNA", feature2 = "nFeature_RNA", gradient = "percent.mt", upper.limit = 100, scale.colors = "viridis")
plot1 + plot2
```

#### 2.2.1 Per-sample QC visualization.

In order to better assess the quality of each individual samples and identify problematic samples, we also explore the QC metrics on each sample.

```{r sample_QC, fig.height=6, fig.width=10}

# Visualize QC metrics as a violin plot
VlnPlot(run1.raw, features = c("nFeature_RNA", "nCount_RNA", "percent.mt"), ncol = 3, group.by = "Sample_Name")
```

```{r}

# Convert Seurat object into a SingleCellExperiment Object for scDblFinder input.
run1.sce <- as.SingleCellExperiment(run1.raw)

# Getting known doublets for adjusting the threshold.
knownDoublets <- run1.raw$Sample_Tag=="Multiplet"

# Load doublet rate and rate error:
BDstats <- readRDS("~/Documents/SC_Prostate/Data/BDstats.rds")

# Set seed for reproducible results with scDblFinder.
set.seed(0)

# Run scDblFinder. Params:
# dbr: The expected doublet rate. We use the output from BD Rapshody for each run.
# dbr.sc: Uncertainty of the doublet rate. We are based on ground truth so we set it to 0.
# knownDoublets & knownUse: The known doublets and how to use it. We use it for training.
run1.sce <- scDblFinder(run1.sce, dbr = BDstats[1], dbr.sd = BDstats[2], knownDoublets = knownDoublets, knownUse = "positive", BPPARAM = BiocParallel::MulticoreParam(workers=detectCores()))

table(truth=run1.sce$Sample_Tag, call=run1.sce$scDblFinder.class)

run1.raw <- as.Seurat(run1.sce, counts = "counts", data = "logcounts", project = "run1")
run1.raw$ident <- NULL
```

### 2.3. Filtering cells.

#### Filtering 1 % top and bottom percentiles.

Taking into account the observed QC parameters and our reduces number of cells, we suggest a soft data-driven filtering method. In our case, we trimmed out the top and bottom 1% of cells according to their gene count, and apply a %mito cutoff of 25%.

We could hard-code the parameters used by the CSIC, but as we cannot know the methodology to decide those values, we prefer to use ours, since obtains pretty similar results. For visualization of the QC, this would be enough.

UPDATE: This is actually the method we will use, since we are going to start from the raw matrix.

```{r filtering_percentiles}

# Remove Undetermined and multiplets.
run1.subset <- subset(run1.raw, Sample_Tag != "Undetermined" & Sample_Tag != "Multiplet" & scDblFinder.class != "doublet")

# Filter the 1% top and bottom percentiles.
minCov <- 1000 # if a sample has a good coverage (>=minCov), then don't set a lower thresold for nCount, it's already pretty good.
if (min(run1.subset$nCount_RNA) >= minCov) {
  countLOW <- min(run1.subset$nCount_RNA)
} else {
  countLOW <- quantile(run1.subset$nCount_RNA, prob = c(0.01))
}
countHIGH <- quantile(run1.subset$nCount_RNA, prob = 0.99)
featureHIGH <- quantile(run1.subset$nFeature_RNA, prob = 0.99)
featureLOW <- quantile(run1.subset$nFeature_RNA, prob = 0.01)

# subset
run1.subset <- subset(run1.subset, subset = nFeature_RNA > featureLOW & nFeature_RNA < featureHIGH & nCount_RNA > countLOW & nCount_RNA < countHIGH & percent.mt < 25)

run1.subset
```

### 2.4. Visualizing QC parameters after filtering.

After filtering we can see that the distribution of mitochondrial DNA improves a bit, and the ration between counts and features is closer to a linear function.

Another thing that don't make sense is the long upper tails of the features and counts distribution. Maybe is possible to apply a more strict cut, but we have to remember we have a low number of cells and there is more data yet to be added.

```{r QC_filter, fig.height=6, fig.width=10}
# Visualize QC metrics as a violin plot
VlnPlot(run1.subset, features = c("nFeature_RNA", "nCount_RNA", "percent.mt"), ncol = 3)

# Zoom in on nCount_RNA violin plot.
VlnPlot(run1.subset, features = "nFeature_RNA", ncol = 1) + ylim(0, 2500)

# Visualize relationships in metadata to detect outliers with FeatureScatter function
plot1 <- FeatureScatter(run1.subset, feature1 = "nCount_RNA", feature2 = "percent.mt")
plot2 <- FeatureScatterGradient(run1.subset, feature1 = "nCount_RNA", feature2 = "nFeature_RNA", gradient = "percent.mt", upper.limit = 100)
plot1 + plot2
```

We can appreciate that after these QC steps samples present very homogeneous QC metrics:

```{r sample_post_QC, fig.height=6, fig.width=10}
# Visualize QC metrics as a violin plot
VlnPlot(run1.subset, features = c("nFeature_RNA", "nCount_RNA", "percent.mt"), ncol = 3, group.by = "Sample_Name")
```

These QC thresholds allow us to equalize QC metrics across samples, improve the correlation between feature count and read depth, trim out dead cells, remove additional undected multiplets and undetermined cells and maximize conservation of cell number.

```{r before and after, fig.height=6, fig.width=10}

# Visualize relationships in metadata to detect outliers with FeatureScatter function
plot1 <- FeatureScatterGradient(run1.raw, feature1 = "nCount_RNA", feature2 = "nFeature_RNA", gradient = "percent.mt", upper.limit = 100)
plot2 <- FeatureScatterGradient(run1.subset, feature1 = "nCount_RNA", feature2 = "nFeature_RNA", gradient = "percent.mt", upper.limit = 100)
plot1 + plot2
```

We need to perform an additional filtering step to remove a group of low feature and read count cells. UPDATE: Because it appears in all batches and it is clustered independently in the merged analysis, we will conseve it and study its cell composition.

```{r additional_trimming}

# Trim out the low-feature low-count cell group.
# run1.subset <- subset(run1.subset, subset = nFeature_RNA > 1000)

# run1.subset
```

```{r trimming_check}

# FeatureScatterGradient(run1.subset, feature1 = "nCount_RNA", feature2 = "nFeature_RNA", gradient = "percent.mt", upper.limit = 100)
```

Save filtered data.

```{r saving_filtered_data, include = FALSE, echo = FALSE}

# Save filtered file for data merging.
saveRDS(run1.subset, file = "~/Documents/SC_Prostate/Data/run1/run1_filtered.rds")
```

## 3. Normalization using SCTransform.

We normalize data using the new SCTransform methodology. This methodology is more precise, more friendly with the original data structure, and offers better clustering results.

The vars.to.regress parameter allows to regress out certain variables, preventing them to have a high impact on PCA dimension reduction and further clustering of samples.

```{r SCTransform}

run1.subset <- SCTransform(run1.subset, vst.flavor = "v2", vars.to.regress = "percent.mt")
```

## 4. Linear dimensional reduction (PCA).

```{r PCA, fig.height=6, fig.width=10}

# Run PCA on the SCT-normalyzed data.
run1.subset <- RunPCA(run1.subset, assay = "SCT") # features = VariableFeatures(object = run2.subset))

DimPlot(run1.subset, reduction = "pca") + NoLegend() # An unique PCA is not enough to separate cell groups.

ElbowPlot(run1.subset, ndims = 50)
```

```{r PCA_heatmap, fig.height=15, fig.width=10}
DimHeatmap(run1.subset, dims = 1:30, balanced = TRUE)
```

```{r PCA_top_features, fig.height=30, fig.width=15}
VizDimLoadings(run1.subset, dims = 1:30, reduction = "pca")
```

## 5. Clustering

In normal circumstances, a selection of the first 20 dims would be enough, but the Seurat developers recommend using a higher amount of PCA dims when using SCTransform.

```{r clustering}
# Resolution fine-tuned in a separate Rmd.
run1.subset <- FindNeighbors(run1.subset, dims = 1:30)
run1.subset <- FindClusters(run1.subset, resolution = 0.8) # Default resolution = 0.8
run1.subset <- RunUMAP(run1.subset, dims = 1:30)
```

```{r cluster_visualization, fig.height=6, fig.width=10}
DimPlot(run1.subset, reduction = "umap", label = TRUE)
```

Cluster QC.

As we can observe, the data structure is conditioned by the abundant presence of mitochondrial DNA. Taking into account the 2 clusters with less % of mitochondrial DNA, clusters 14 and 15, we appreciate how the lower content in mitochondrial material correlates with lower feature and read counts. On the other hand, if we compare the distritrubution of mitoDNA of each cluster with the feature and count distribution, we can see a clear similarity.

Thus, mitochondrial DNA is shaping the data, and probably conditioning the cell annotation and further analysis.

```{r cluster_QC, fig.height=6, fig.width=10}
# Visualize QC metrics as a violin plot
VlnPlot(run1.subset, features = c("nFeature_RNA", "nCount_RNA", "percent.mt"), ncol = 3) + NoLegend()

# Zoom in on nFeature_RNA violin plot.
VlnPlot(run1.subset, features = "nFeature_RNA", ncol = 1) + ylim(0, 2500) + NoLegend()

# Visualize relationships in metadata to detect outliers with FeatureScatter function
plot1 <- FeatureScatter(run1.subset, feature1 = "nCount_RNA", feature2 = "percent.mt")
plot2 <- FeatureScatter(run1.subset, feature1 = "nCount_RNA", feature2 = "nFeature_RNA")
plot1 + NoLegend() + plot2 + NoLegend()
```

## 6. Annotation.

Cell annotation is performed using the Human Cell Atlas as reference.

SingleR.annotation uses the logcounts provided in the count matrix of the SingleCellExperiment object by default. Nevertheless, after applying SCTransform, counts and logcounts are both the normalized counts (so both values are the same).

```{r annotation}
# Using celldex and SingleR packages.
# Download reference data from celldex.
reference <- HumanPrimaryCellAtlasData()

# Convert Seurat object into a SingleCellExperiment Object for SingleR input.
run1.SCexp <- as.SingleCellExperiment(run1.subset)

# Anotate using raw counts.
SingleR.annotation <- SingleR(test = run1.SCexp, ref = reference, assay.type.test = "logcounts", labels = reference$label.main, num.threads = detectCores())

run1.subset[["cell.labels"]] <- SingleR.annotation$labels
```

```{r annotation_vis, fig.height=6, fig.width=10}
DimPlot(run1.subset, reduction = "umap", group.by = "cell.labels", label = TRUE, repel = TRUE, label.size = 4) + theme(axis.title = element_text(size = 15), legend.text = element_text(size = 10), axis.text = element_text(size = 10)) + guides(colour = guide_legend(override.aes = list(size = 3)))
```

You can also obtain the anotation on a cluster-by-cluster method based rather than a cell-by-cell one. By cluster annotation:

```{r}
clusters <- run1.subset@meta.data[["seurat_clusters"]]
clusters <- as.character(levels(clusters)[clusters])
```

```{r cluster_annotation}
# Obtaining a vector containing the cluster of each cell in order.

# Get the factor contained in the SeuratObject with all this information.
clusters <- run1.subset@meta.data[["seurat_clusters"]]

# The cluster information for each cell is contain as a factor which levels coincide with the total number of clusters found by FindClusters(). An approach to transform this factor into a character vector is the following:
# Obtain the list of clusters with levels(clusters). This outputs a character vector containing the levles of the factor. After that, we use the factor itself as an index to access the levels vector. When using a factor as an index, R does not use the labels itself (which in this case are string, so if used as indexes would cause an error), but the internal numeric index the factor contains. That way, for each cluster label assosiated with a cell in the factor, we access its numeric index and map it to the levels vectors (which coincides), thus obteinin each cell label as an unique character value. Each cell label is then storage as a character (the as.character is added as a control method since SingleR only admits strings as labels) in a vector. The vector contains the cluster label for each cell as a character value in the same order as each cell appears in the dataset, so the by-cluster annotation doesn't assing the cells to an incorrect cluster.
clusters <- as.character(levels(clusters)[clusters])

# reference <- HumanPrimaryCellAtlasData()

run1.SCexp <- as.SingleCellExperiment(run1.subset)

# We input the cluster vector using the clusters parameter.
SingleR.annotation <- SingleR(test = run1.SCexp, ref = reference, assay.type.test = "logcounts", labels = reference$label.main, clusters = clusters, num.threads = detectCores())

run1.subset[["cluster.labels"]] <- SingleR.annotation$labels
```

```{r set_ids}
# We composite the cluster name. That way when 2 clusters name are the same Seurat doesn't merge the labels.

# Get clusters levels accesing the SeuratObject variable as a df and then accesing the df as a column.
cluster_number <- levels(run1.subset[["seurat_clusters"]][1, ])

# Get annotation labels.
cluster_annotation <- SingleR.annotation$labels

# Since cluster levels and labels are in the same order, we composite the new names using paste0 (sort of equivalent to fstrings in python).
new.clusters.ids <- paste0(cluster_number, "-", cluster_annotation)

# Add names to each value of the clusters id vector so Seurat can take it as a valid input for RenameIdents.
names(new.clusters.ids) <- levels(run1.subset)
run1.subset <- RenameIdents(run1.subset, new.clusters.ids)
```

```{r cluster_annotation_vis, fig.height=6, fig.width=10}
DimPlot(run1.subset, reduction = "umap", label = TRUE, repel = TRUE, label.size = 4) + theme(axis.title = element_text(size = 15), legend.text = element_text(size = 10), axis.text = element_text(size = 10)) + guides(colour = guide_legend(override.aes = list(size = 3)))
```

```{r saving_data, include = FALSE, echo = FALSE}

# Save filtered file for data merging.
saveRDS(run1.subset, file = "~/Documents/SC_Prostate/Output/run1/run1_processed.rds")
```

Session info.

```{r session_info}

sessionInfo()
```